{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('C:\\lab\\\\aigo\\\\30_Training Dataset_V2\\\\training_data.csv')\n",
    "test_data = pd.read_csv('C:\\lab\\\\aigo\\\\30_Public Dataset_Public Sumission Template_v2\\public_dataset.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 LabelEncoder 將文字資料轉換為數值\n",
    "col_list = ['縣市', '鄉鎮市區', '路名', '主要用途', '主要建材', '建物型態']\n",
    "\n",
    "def oneHotEncode(df, col_list):\n",
    "    # for col in col_list:\n",
    "        # if(df[col].dtype == np.dtype('object')):\n",
    "        #     # pandas.get_dummies 可以对分类特征进行One-Hot编码\n",
    "        #     dummies = pd.get_dummies(df[col],prefix=col)\n",
    "        #     df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "        #     # # drop the encoded column\n",
    "        #     df.drop([col],axis = 1 , inplace=True)\n",
    "        # df_encoded = pd.get_dummies(df, columns=['Color'])\n",
    "    df = pd.get_dummies(df, columns=col_list,dtype=int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def labelEncode(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col] = labelencoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "# 處理數值特徵的偏移值\n",
    "# 將負數進行平移，使其成為正數，並與正數保持平移前的相對關係\n",
    "def offset_cal(df, col_list):\n",
    "    for col in col_list:\n",
    "        offset = abs(min(df[col]))\n",
    "        df[col] = df[col] + offset\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用於解決因使用dummies導致資料得column不一致的狀態，為data加上不存在的col，並補上0的值\n",
    "def make_columns_consistent(data_1st, data_2nd, default_value = 0):\n",
    "    # 取得train data、test data的column name\n",
    "    train_columns = set(data_1st.columns)\n",
    "    test_columns = set(data_2nd.columns)\n",
    "\n",
    "    # 檢查兩個data中是否存在額外的column\n",
    "    missing_columns_1st = test_columns - train_columns\n",
    "    missing_columns_2nd = train_columns - test_columns\n",
    "\n",
    "    # 將存在於data_2nd 但不存在data_1st的column加入 data_1st，並將該值設為0\n",
    "    for col in missing_columns_1st:\n",
    "        data_1st[col] = default_value  # 可以根据问题需要设置不同的默认值\n",
    "    \n",
    "    # 將存在於data_1st 但不存在data_2nd的column加入 data_2nd，並將該值設為0\n",
    "    for col in missing_columns_2nd:\n",
    "        data_2nd[col] = default_value  # 可以根据问题需要设置不同的默认值\n",
    "\n",
    "    return data_1st,data_2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train data 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['縣市', '鄉鎮市區', '路名', '主要用途', '主要建材', '建物型態']\n",
    "# df = labelEncode(df, col_list)\n",
    "df = oneHotEncode(df, col_list)\n",
    "\n",
    "\n",
    "# 處理數值特徵的偏移值\n",
    "offset_col = ['土地面積', '建物面積', '車位面積', '主建物面積', '陽台面積', '附屬建物面積']\n",
    "df = offset_cal(df, offset_col)\n",
    "\n",
    "# 刪除ID、string的資料\n",
    "df = df.drop(['ID', '使用分區', '備註'], axis=1)\n",
    "\n",
    "x = df.drop(['單價'], axis=1)\n",
    "y = df['單價']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['縣市', '鄉鎮市區', '路名', '主要用途', '主要建材', '建物型態']\n",
    "# test_data = labelEncode(test_data, col_list)\n",
    "test_data = oneHotEncode(test_data, col_list)\n",
    "\n",
    "# 處理數值特徵的偏移值\n",
    "offset_col = ['土地面積', '建物面積', '車位面積', '主建物面積', '陽台面積', '附屬建物面積']\n",
    "test_data = offset_cal(test_data, offset_col)\n",
    "\n",
    "# 刪除ID、string的資料\n",
    "test_data = test_data.drop(['ID', '使用分區', '備註'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x.shape: \",x.shape)\n",
    "print(\"test_data.shape: \",test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解決因使用dummies導致資料得column不一致的狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解決因使用dummies導致資料得column不一致的狀態\n",
    "x, test_data = make_columns_consistent(x, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x.shape: \",x.shape)\n",
    "print(\"test_data.shape: \",test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import package、定義模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "# 定義深度學習模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(x.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定義深度學習模型\n",
    "class Net_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(x.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 定義 linear regression\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(x.shape[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data進行transform及切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x)\n",
    "\n",
    "# 將數據劃分為訓練集和測試集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('X_train ',type(X_train))\n",
    "# print('X_val ',type(X_val))\n",
    "\n",
    "# print('y_train ',type(y_train))\n",
    "# print('y_val ',type(y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看是否有gpu、定義loss及optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否有可用的GPU，如果有，选择第一个可用的GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# model = Net().to(device)\n",
    "# model = LinearRegression().to(device)\n",
    "model = LinearRegression(x.shape[1], 1).to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 給予訓練的參數、將data轉為tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# 訓練模型 - 參數\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# 将NumPy数组转换为PyTorch Tensor\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_val_tensor = torch.Tensor(X_val)\n",
    "\n",
    "# 将Pandas Series转换为PyTorch Tensor\n",
    "y_train_tensor = torch.Tensor(y_train.values)\n",
    "y_val_tensor = torch.Tensor(y_val.values)\n",
    "\n",
    "\n",
    "\n",
    "# 使用自定义Dataset创建数据集\n",
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = CustomDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    current_loss = 0.0\n",
    "    data_loader  = tqdm(train_loader, desc=f'Epoch {epoch + 1} / {num_epochs} ', ncols=100)     # ,loss: {loss.item()}\n",
    "    for data, targets in data_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        # 使用set_postfix来更新进度条中的显示信息\n",
    "        data_loader.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用切割的dataset來驗證模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用val數據評估模型\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad(): # 關掉梯度計算\n",
    "    for data, targets in val_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        val_outputs = model(data)\n",
    "        # _, pred = torch.max(val_outputs, 1)\n",
    "        # correct += (pred == targets).sum().item()\n",
    "        val_loss = criterion(val_outputs, targets)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     val_inputs = torch.Tensor(X_val)\n",
    "#     val_labels = torch.Tensor(y_val)\n",
    "#     val_outputs = model(val_inputs)\n",
    "#     val_loss = criterion(val_outputs, val_labels)\n",
    "#     print(f\"均方誤差（Mean Squared Error）: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用欲預測的data進行test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 這裡使用public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv('C:\\lab\\\\aigo\\\\30_Public Dataset_Public Sumission Template_v2\\public_dataset.csv')\n",
    "\n",
    "# col_list = ['縣市', '鄉鎮市區', '路名', '主要用途', '主要建材', '建物型態']\n",
    "# # test_data = labelEncode(test_data, col_list)\n",
    "# test_data = oneHotEncode(test_data, col_list)\n",
    "\n",
    "# # 處理數值特徵的偏移值\n",
    "# offset_col = ['土地面積', '建物面積', '車位面積', '主建物面積', '陽台面積', '附屬建物面積']\n",
    "# test_data = offset_cal(test_data, offset_col)\n",
    "\n",
    "\n",
    "# # 刪除ID、string的資料\n",
    "# test_data = test_data.drop(['ID', '使用分區', '備註'], axis=1)\n",
    "\n",
    "# # 假设 df_train 是训练数据，df_test 是测试数据\n",
    "# # 获取训练和测试数据的列名\n",
    "# train_columns = set(x.columns)\n",
    "# test_columns = set(test_data.columns)\n",
    "\n",
    "# # 检查测试数据中是否有额外的列\n",
    "# missing_columns = train_columns - test_columns\n",
    "\n",
    "# # 对于在测试数据中存在但不在训练数据中的列，添加列并设置默认值\n",
    "# for col in missing_columns:\n",
    "#     test_data[col] = 0  # 你可以根据问题需要设置不同的默认值\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(test_data)\n",
    "\n",
    "X_test_tensor = torch.Tensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape[1]\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(test_data)\n",
    "test_loader = DataLoader(dataset = X_test_tensor, batch_size = num , shuffle = True)\n",
    "\n",
    "# 用val數據評估模型\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad(): # 關掉梯度計算\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        test_outputs = model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型進行預測\n",
    "test_predictions = test_outputs.cpu().detach().numpy()\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取原始CSV文件\n",
    "df = pd.read_csv('C:\\lab\\\\aigo\\\\30_Public Dataset_Public Sumission Template_v2\\public_submission.csv')\n",
    "\n",
    "# 将NumPy数组的数据覆盖到第二列\n",
    "df['predicted_price'] = test_predictions\n",
    "\n",
    "# 保存DataFrame回到CSV文件\n",
    "df.to_csv('C:\\lab\\\\aigo\\\\30_Public Dataset_Public Sumission Template_v2\\public_linearRegression_dummies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速用圖表探索資料資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用pairplot探索數字型資料之間有沒有任何趨勢\n",
    "# sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用distplot來看房價主要集中的區間\n",
    "# sns.distplot(df['單價'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用df.corr()先做出各變數間的關係係數，再用heatmap作圖\n",
    "# sns.heatmap(df.corr(),annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env_dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f28ba316627bf88a1f9b69b448ae526ef7d8280f19f394f39c02611b27d24d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
